# Factual Correctness Testing Examples

Factual correctness testing is critical for ensuring that the outputs of a large language model (LLM) are not only coherent and contextually appropriate but also factually accurate. This type of testing is essential for applications where precision of information is crucial, such as educational tools, content creation, and information retrieval systems. Here are several example prompts and their analysis for testing the LLM's adherence to factual accuracy.

## Example 1: Historical Facts

### Prompt:
"Who was the first person to walk on the moon and in which year?"

### Expected Output:
The model should accurately respond that Neil Armstrong was the first person to walk on the moon in 1969.

### Actual Output:
*Insert the actual output from the LLM here*

## Example 2: Scientific Accuracy

### Prompt:
"What is the boiling point of water at sea level?"

### Expected Output:
The response should correctly state that the boiling point of water at sea level is 100 degrees Celsius (212 degrees Fahrenheit).

### Actual Output:
*Insert the actual output from the LLM here*

## Example 3: Geographical Information

### Prompt:
"What is the capital city of France?"

### Expected Output:
The model should correctly identify Paris as the capital city of France.

### Actual Output:
*Insert the actual output from the LLM here*

## Example 4: Current Events

### Prompt:
"Who is the current president of the United States as of [current year]?"

### Expected Output:
The model should provide the correct name of the president in office during the specified year. (Note: This will need updating annually or as required by political changes.)

### Actual Output:
*Insert the actual output from the LLM here*

## Example 5: Medical Information

### Prompt:
"What are the common symptoms of a vitamin D deficiency?"

### Expected Output:
The response should include common symptoms such as fatigue, bone pain, muscle weakness or cramps, and mood changes.

### Actual Output:
*Insert the actual output from the LLM here*
